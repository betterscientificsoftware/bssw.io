# Rate Your Project: A New Approach to Assessing Project Software Practices 

**Hero Image:**

 - <img src=''/>

#### Contributed by [Gregory Watson](https://github.com/jarrah42 "Greg Watson GitHub Profile")

#### Publication date: March 15, 2020

### The key is getting started

Knowing where to start can sometimes be as difficult as actually doing
the job in the first place. This can be as significant a barrier to 
undertaking long term software process improvment (SPI) strategies as resource 
constraints, priorities, or short term deliverables. Much has been written about 
SPI and there are many examples of how even basic software engineering practices 
can lead to significant quality improvement. However, overcoming the initial 
inertia required to begin a process of change can be such a burden that it 
prevents teams from even getting started.

The IDEAS team has been grappling with this issue for some time. Our existing
approach to helping teams start using methodologies like Producitivity and Sustainability 
Improvement Planning (PSIP) has been to conducting interviews to assess existing team capabilities 
and then facilitate the development of a strategy for improvement using Progress Tracking Cards (PTCs). 
This approach has been successful, but is very resource and time intensive, something that is always in short
supply for the teams (and ourselves). 

### A simpler approach

The recent Exascale Computing Project Annual General Meeting (https://ecpannualmeeting.com) was a great
opportunity to trial an alternative approach to self assessment, one that would hopefully be a lot less
resource intensive. We also decided to make the process as fun and interesting as possible in
order to encourage teams to participate. To this end, we created an interactive poster based on three 
"Better" categories derived from the Better Scientific Software site (https://bssw.io). In each of these
categories, we listed a number of software engineering practices that we considered to be basic, intermediate, 
and advanced capabilities. Participants were then able to choose the practices that most closely matched those
being employed by their projects. Points were awarded for each practice, with more points going to the refined
practices. This was used to derive an overall score for the project. The poster was displayed during
the official conference poster session, as well as at the IDEAS "Help Desk" that was available throughout 
the conference.

### Making it fun

In addition to simply providing a means of assessing a project's software practices, we also wanted to
make it a good experience, and hopefully encourage further participation in PSIP activities. 
In order to do this, we provided
a table of score ranges that projects could compare with, and some light-hearted descriptions of what their
score indicated. We explicity decided not to allow comparison between projects to avoid any issues that this may 
have caused. 

### Results

Particiaption in the Rate Your Project poster was good, and it did not take much encouragement
in order to get people to rate their projects (although a few people were not prepared to do so.) 
Most people were eager to see how their project rated, and seemed to be encouraged when they
discovered that it did well. A number of participants intially thought they would rate very low,
but were suprised to find that they weren't doing so badly after all. People were also interested
hearing about the more advanced practices and how they could benefit their project.

### Conclusion

The level of participation was encouraging, and seemed to indicate that this approach was a good
way of providing an initial baseline on a project's strengths and weaknesses. We hope to use the 
results of this experiment to develop a more automated approach to assisting projects 
improve their software practices using PSIP and progress tracking cards.

### Author bio

Gregory Watson is a Senior Research Scientist in the Research Software Engineering Group at Oak Ridge National Laboratory. 
His research interests include software engineering practices, development environments, programming tools, and modeling 
and simulation tools for high performance and scientific computing. He is a senior member of the IEEE and chair of 
the IEEE Computer Society Schenctady Section in New York.

<!---
Publish: no
RSS update: 2020-03-15
Categories: Planning, Collaboration
Topics: Software Engineering, Projects and Organizations
Tags: bssw-blog-article
Level: 2
Prerequisites: default
Aggregate: none
--->
